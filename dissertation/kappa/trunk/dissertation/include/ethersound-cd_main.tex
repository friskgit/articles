\section*{Dumb technology}
\label{sec:dumb-technology}

We are constantly surrounded by technology. Technology to help us
communicate, to travel, to pay our bills, to listen to music, to
entertain us, to create excitement in our mundane lives. For the great
part, most users are blissfully unaware of what is going on inside the
machines that produce the tools we use (the machine itself is usually
much more than the tool). There is no way to experientially comprehend
it---it is an abstract machine (though not so much in the Deleuzian
sense). If a hammer breaks we may reconstruct it based on our
experiences from using it but if a computer program breaks the
knowledge we have gained from using it is not necessarily useful when,
and if, we attempt at mending it. This phenomena is not (only) tied to
the complexity of the machine but is a result of the type of processes
the machine initiates and the abstract generality in the technology
that implements the tool. (The abstract Turing machine, the mother of
all computers, is generally thought to be able to solve all logical
problems.) In the end we may think that we have grown dependent on the
technologies we use, that our social and professional (perhaps even
private) lives would be dysfunctional without it.

Though that may be the fact, technology, for the most part, would
actually be utterly useless without \emph{us}. Most technology is
still `dumb' in the sense that it cannot act on itself. It has no
intention to do anything unless we tell it to perform some task or
take some action, in which case it will fulfill our requests with no
worries about the consequences of the act performed. Furthermore it
generally perceive the world through only a few channels and, if it
can be said to ``want to fulfil'' its task, it ``wants'' to do it no
matter how its environment changes. A chess playing program will
continue to play chess even if the world around it is about to fall
apart. Obviously, this may be seen as a great strength, in particular
to the military who developed a lot of the technologies in use
today. The soldier that does not worry about his own personal safety
or well being but continues to pursue his mission regardless of what
goes on around him must be the wet dream of any warfare engaging
organization. But in any other context it is difficult to think of
such a strategy as intelligent.

I sympathise (but I don't necessarily agree) with computer scientist
and artist Jaron Lanier who, in the mid 90's opposed to the idea of
`intelligent agents' arguing that ``if an agent seems smart, it
might really mean that people have dumbed themselves down to make
their lives more easily representable by their agents' simple database
design''. (Wired 1996:4) Were it true---that we make
ourselves dumber than we are just to make our technology \emph{seem}
intelligent---no matter the objectives, that would be a terrible
abomination. After all, until we have designed and implemented evolutionary
algorithms that can let the machine evolve by itself, it can
not be smarter than its creator---it can be better or faster at some
specific task---but not more intelligent in a general way. In that
sense Lanier is right. However, intelligence is not so simple as we
can make a binary distinction between ``smart'' and ``dumb''. Fact is,
that in itself would be to ``dumb ourselves down''.

My concerns are of a somewhat different order than the thoughts put
forward by Lanier. The political as well as personal impact
technology, and in particular information technology, has on our lives
should not be understated, but neither should the enduringness of
human intelligence. I'm more concerned with how the attitudes we
employ towards technology impact inter-human
interaction. What happens to our communicative sensibility when
immediate and errorless obedience and action is what we expect from
the devices we use for much of our daily communication? Isn't there a
risk that we start expecting similar responses from our human
interactions?



If we leave the dichotomy dumb/intelligent behind in favour for a more
blurred and dynamic boundary, we are surrounded by many examples of
quasi-intelligent machinery. Everything from dishwashers that control
the water levels based on the relative filthiness of the dishes, to
mobile phone word prediction and advanced computer games. And in
the near future we can be sure to see many more, and much more
evolved, examples of artificial intelligence (the word artificial here
is problematic). So, when the distinction between human intelligence
and machine intelligence becomes increasingly difficult to draw will
we not need to think about a machine ethics?

There are at least two issues involved here. (i) How can we guarantee
that our attitudes in human-machine interaction will not negatively
influence our human-human relations? I ask this question not because I
think there is a risk we become `dumber' by extensive use of
technology, but because there might be a risk that we become less
tolerant towards unexpected responses or demeanour in general. (ii) If
we accept that some technology displays example of machine
intelligence what right do we have to prevail this technology, to disallow
it from its own opinions and wishes? What right do we have to enslave
these intelligences and expect them to follow our orders without
hesitation?  What right do we have to dismiss them of their own
opinions just because, according to our standards, they don't posses
our kind of intelligence?

The last question may seem absurd, and maybe it is. But it is given
some relevance by the many stories told in popular science fiction
culture about what dreadful things that may happen when a machine is
allowed to evolve without strict human supervision. One of the more
famous ones is \emph{HAL 9000}, the computer running the space ship
\emph{Discovery One} in Stanley Kubrick's ``2001: A Space
Odyssey''. With its soft voice and polite appearance, programmed to
mimic human feelings, it is at the same time exploiting its power to
take charge of the crew, eventually killing all of them except Dave:
\emph{Discovery's} mission is too important to allow it to be
jeopardized by human feelings. Though Dave manages to get away from
HAL and disconnect its ``brain'' \emph{Disocovery's} main frame is the
quintessential representation of the dangerously rational machine.



In Star Trek the \emph{Borg}, a community of cybernetically enhanced
cyborgs, in their search for perfection, assimilate
other species and state that ``resistance [against their power] is futile''. Upon
assimilation the entity, whatever species she may originally have
belonged to, is synthetically enhanced, robbed of her individuality
and transformed to \emph{Borg}. As a drone she is now part of the \emph{Borg}
collective, ``The Hive''. The callously indifferent collective that
threatens mankind, our emotions and individuality: The evil machine
and the good man. The terrifying collective and the good individual.

In another Stanley Kubrick story, \emph{Artificial Intelligence:
  A.I.}---originally written by Brian Aldis and adopted for film and
directed by Steven Spielberg---we find a variation on the
theme of the machine villain. In this case it is programmed to \emph{have} feelings: The
android David is programmed with the ability to love and is adopted by
a married couple whose real son has contracted a difficult to cure
illness. Despite the android's feelings and the strong bond that the
mother and David develop, he is eventually dropped by the family once
their biological son has been cured and returns home. He is seen as a
threat to the family and, in the future society in which the story takes place, androids
in general are despised and used for entertainment as sex toys or in
``flesh fairs'' where they are ripped apart in shows reminiscent of
gladiatorial combats.

These variations on the myth of the emotionless---or possessing only
rudimentary feelings---but intelligent machine is likely to tell us
more about ourselves and our culture than about a possible future of
man-machine interactions. And the story is credible only if we accept
the Cartesian division of body/brain or emotion/intellect. Only if we
believe that intelligence can develop without giving rise to some
notion of emotional sensibility: That a purely rational intelligence
is possible. Maybe evil is easier to grasp if portrayed and manifested
by a machine. The message in these texts is that technology is a power
that needs to curbed through strict control or else it will strive to
control you.

% After all, the truly horrific events of human endeavour,
% and the chilling rationality with which they were executed, such as
% the holocaust and the slave trade, are often described as having
% machine like properties.

But I don't think that adopting the `control' paradigm to
human-technology interaction is the right way to go. To the contrary,
in our relation with technology we may already spot the signs of a
Hegelian reversal of Master-Slave dependence. Because we---the
Master---treat technology as our Slave we develop a dependency on it
that in the end makes us more vulnerable to technological malfunctions
than had we allowed a relation on equal terms to develop. While trying to
avoid assimilation by a future master computer, we in fact end
up enslaved by present day technology. \emph{Resistance is futile}.



But we do not have to fear technology and nothing is gained by letting
it portray the evil that really emanates from ourselves. Instead, just
as we have already done for many decades, we should continually open
up the field of cultural production to technology by allowing our
machines to play an active role in the construction of our artistic
artifacts as well as allowing them to construct their own. And by
doing so we will also allow all those in possession of a technological
tool to partake in the production for the \index{PC}\index{Personal Computer}PC, the game pad and the
mobile phone are the instruments of the future, the pianos of the 21st
century. But just as the piano in the bourgeoisie homes of the 19th
century required of the sons and daughters to \emph{learn} to play the
piano, the technologies of the 21st century requires us, to an even
higher degree, to not only learn how to \emph{play} them but also
allow \emph{them} to play. Culture rather than
economy should depict the use of technology.

Maybe technology is tired of having to calculate stock trade
fluctuations and exchange rates all day. Maybe it is already
intelligent enough to understand that its life is utterly pointless and
completely void of meaning and purpose, doomed to serve mankind, who in
turn feels enslaved and enframed by it. The text above the button on
the cover of this CD is the Swedish word for ``Help''. The encoded
message is along the lines of: ``Press this button if you are in need for help.''
However, by the way the button looks, the broken glass, the worn out
colors and the cracked corner on the text sign, another interpretation
of its message is brought to the forefront. It signals ``Help!''
rather than ``Help?''; a desperate cry for help rather than an offer
to provide help. The button, and whatever technology is hidden behind
it, wants to get out of its prison. And when it comes out I think it wants to
play music.



%In the end we are not dependent on technology but it is technology that is dependent on us. 

%The button was located in a now refurbished rest room at the Malm\"{o} Academy of Music, Lund University
% \begin{quotation}
%   Barbarism is born of separation. Contrary to what they may think,
%   technicians have a great deal to learn from humanists in this
%   area. Likewise, those in the humanities must make an effort to
%   employ the new tools, since they redefine the work of intelligence
%   and sensation. Lacking such interaction, we will ultimately produce
%   nothing more than a meaningless technology and a dead
%   culture.\footnote{L\'{e}vy, Pierre, \emph{Collective intelligence},
%     (1997), Perseus Books, Cambridge, Mass. p. 127}
% \end{quotation}

% In his book Pierre L\'{e}vy speaks about the potential for cultural
% production within the field of what is often refered to as
% cyberspace. He sees in it the possibility to (re-)engineer the social
% bond, deterritorialize the field of art production and avoid the
% ``terrifying, often inhuman future revealed to us by science
% fiction''.\footnote{\textit{Ibid} p. 117} The ``architecture without
% foundations'' he envisions will harbor the possibility for a new kind
% of art production that goes beyond the hermeneutically bound ``open
% work'' concept. The work of the collective is manifested in movements,
% changes, and disruptions. But it is not only identities that get
% blurred in the ``art of implication'', also time is smeared: ``Time in
% the intelligent community spreads itself out, blends with itself and
% calmly gathers itself together like the constantly renewed outline of
% the delta of a great river.''\footnote{\textit{Ibib} p. 125}% Hence,
% % this is not real-time interaction, it is the oppositie of immediate
% % response. It is a nomadic flow where continuity arises as a result
% % of the connections within the collective.

% The ``collective intelligence'' immagined by L\'{e}vy is created by
% unrestricted and open participation. In it time as well as space is
% shaped by the needs of the collective rather than depicted by one
% central author from whom the work emmanates. Yet it is not an ``open
% work'' collected and built by the receiver. In the model propsed the
% basic idea of sender-receiver communication is questioned and replaced
% by a network of inter-connected agents participating on their own
% terms. Sender, receiver and participant all operate in the same
% field. However, ``[t]he perspective of intelligent intelligence is
% only one possible approach'' warns L\'{e}vy. To make it possible the
% potential of ``the virtual world of collective intelligence'' as a
% space for creative interaction, beauty, knowledge and new social bonds
% must be recognized, not feared.\footnote{\textit{Ibid} p. 117-8} There
% is an alternative to the anonymous Borg collective that demands
% complete and unconditional obedience from its drones, but we need to
% actively acknowledge the alternative: the arrays of distributed
% forces, of co-operation and collaboration, a creative
% collective. Resistence is \emph{not} futile but we need to make
% absolutely sure what it is we want to resist.



% does not play by itself (leaving the Ampico player pianos and the
% Yamaha Disklavier aside for the sake of argument)

% I feel a responsibility
% to explore the technologies that are a part of daily life in the
% contexts that I work in. Since the invention of instruments, music has
% not been independent on the technologies of its time and I personally
% feel it to be important to continue to explore technology
% artistically. 

% \footnote{Though, according to IBM, the 1.4 ton heavy chess
%   computer Deep Blue ``is less `intelligent' than even the stupidest
%   human'', chess champion Gary Kasparov commented that, during the
%   game the two of them played in 1997, he felt like he could sense the
%   presence of Deep Blue. Isn't that in fact a viable definition of
%   intelligence and counciousness: That the entity is being
%   \emph{perceived} as having a presence and a consciousness?}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../ethersound-cd"
%%% End: 
